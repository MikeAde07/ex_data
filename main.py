import streamlit as st
from langchain_experimental.agents import create_csv_agent
from langchain.agents import Tool, initialize_agent
from langchain_experimental.tools.python.tool import PythonREPLTool
from langchain.llms import OpenAI
from dotenv import load_dotenv
from vector import process_to_csv_chroma, get_vector_retriever
from langchain.memory import ConversationBufferMemory
from htmlTemplates import css, bot_template, user_template
import pandas as pd


def main():

    # access to env variables
    load_dotenv()

    #streamlit front-end setup
    st.set_page_config(page_title="AI CSV Agent + RAG ðŸ“ˆ")
    st.write(css, unsafe_allow_html=True)
    st.header("Ask your CSV - with Semantic RAG + Agent ðŸ“ˆ")

    if st.button("ðŸ§¹ Clear Chat", key="clear_chat_button"):
        st.session_state.clear()
        

    #session state for chat memory and UI
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if "agent_memory" not in st.session_state:
        st.session_state.agent_memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        

    #Upload csv
    user_csv = st.file_uploader("Upload your CSV file", type="csv")

    # test if csv is loaded
    if user_csv is not None :
        user_question = st.text_input("Ask a question about your CSV:")

        #welcome message
        if not st.session_state.chat_history:
            st.write(user_template.replace("{{MSG}}", "Hello Agent!"), unsafe_allow_html=True)
            st.write(bot_template.replace("{{MSG}}", "Hello!"), unsafe_allow_html=True)


        #upload csv to vectordb
        process_to_csv_chroma(user_csv)
        retriever = get_vector_retriever()

        #Reset file pointer before reading again
        user_csv.seek(0)

        #Load CSV into DataFrame for code tool
        df = pd.read_csv(user_csv)

        #RAG Tool
        def rag_tool_fn(query: str) -> str:
            docs = retriever.get_relevant_documents(query)
            return "\n".join([doc.page_content for doc in docs])
        
        rag_tool = Tool(
            name="RAGSearchTool",
            func=rag_tool_fn,
            description="Use this to semantically search the CSV content and retrieve relevant context."
        )

        #Pandas tool (code execution over DataFrame)
        python_tool = PythonREPLTool(locals={"df": df})

        # Tool list
        tools = [rag_tool, python_tool]

        #initializing our LLM and agent
        llm = OpenAI(temperature=0)

        agent = initialize_agent(
            tools=tools,
            llm=llm, 
            agent_type="zero-shot-react-description", 
            verbose=True,
            memory=st.session_state.agent_memory, 
            allow_dangerous_code=True)

        if user_question is not None and user_question != "" :
           # response generated by our agent after it being passed the user question
            response = agent.run(user_question)


            #Store Q&A in streamlit session for display
            st.session_state.chat_history.append({"role": "user", "content": user_question})
            st.session_state.chat_history.append({"role": "agent", "content": response})

        #Render chat history in UI
        for msg in st.session_state.chat_history:
            if msg["role"] == "user":
                st.write(user_template.replace("{{MSG}}", msg["content"]), unsafe_allow_html=True)
            else:
                role="Agent"
                st.write(bot_template.replace("{{MSG}}", msg["content"]), unsafe_allow_html=True)
        
            

if __name__ == "__main__":
    main()